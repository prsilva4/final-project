{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a567b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3b8085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3738</td>\n",
       "      <td>destroyed</td>\n",
       "      <td>USA</td>\n",
       "      <td>Black Eye 9: A space battle occurred at Star O...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>853</td>\n",
       "      <td>bioterror</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#world FedEx no longer to transport bioterror ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10540</td>\n",
       "      <td>windstorm</td>\n",
       "      <td>Palm Beach County, FL</td>\n",
       "      <td>Reality Training: Train falls off elevated tra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5988</td>\n",
       "      <td>hazardous</td>\n",
       "      <td>USA</td>\n",
       "      <td>#Taiwan Grace: expect that large rocks trees m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6328</td>\n",
       "      <td>hostage</td>\n",
       "      <td>Australia</td>\n",
       "      <td>New ISIS Video: ISIS Threatens to Behead Croat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>4377</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>#Earthquake #Sismo M 1.9 - 15km E of Anchorage...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>3408</td>\n",
       "      <td>derail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@EmiiliexIrwin Totally agree.She is 23 and kno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>9794</td>\n",
       "      <td>trapped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hollywood Movie About Trapped Miners Released ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>10344</td>\n",
       "      <td>weapons</td>\n",
       "      <td>Beirut/Toronto</td>\n",
       "      <td>Friendly reminder that the only country to eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>1779</td>\n",
       "      <td>buildings%20on%20fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buildings are on fire and they have time for a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6471 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                keyword               location  \\\n",
       "0      3738              destroyed                    USA   \n",
       "1       853              bioterror                    NaN   \n",
       "2     10540              windstorm  Palm Beach County, FL   \n",
       "3      5988              hazardous                    USA   \n",
       "4      6328                hostage             Australia    \n",
       "...     ...                    ...                    ...   \n",
       "6466   4377             earthquake              ARGENTINA   \n",
       "6467   3408                 derail                    NaN   \n",
       "6468   9794                trapped                    NaN   \n",
       "6469  10344                weapons         Beirut/Toronto   \n",
       "6470   1779  buildings%20on%20fire                    NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Black Eye 9: A space battle occurred at Star O...       0  \n",
       "1     #world FedEx no longer to transport bioterror ...       0  \n",
       "2     Reality Training: Train falls off elevated tra...       1  \n",
       "3     #Taiwan Grace: expect that large rocks trees m...       1  \n",
       "4     New ISIS Video: ISIS Threatens to Behead Croat...       1  \n",
       "...                                                 ...     ...  \n",
       "6466  #Earthquake #Sismo M 1.9 - 15km E of Anchorage...       1  \n",
       "6467  @EmiiliexIrwin Totally agree.She is 23 and kno...       0  \n",
       "6468  Hollywood Movie About Trapped Miners Released ...       1  \n",
       "6469  Friendly reminder that the only country to eve...       1  \n",
       "6470  Buildings are on fire and they have time for a...       1  \n",
       "\n",
       "[6471 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample= pd.read_csv('labeled.csv')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33b863c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3674\n",
       "1    2713\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = sample.drop_duplicates('text', keep='last')\n",
    "sample['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96f56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_up(s):\n",
    "    \n",
    "    lower = s.lower()\n",
    "    no_url = re.sub('http\\S+', '', lower)\n",
    "    str_list = re.findall('[a-z]+', no_url)          \n",
    "    \n",
    "    return ' '.join(str_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06b0310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rafaelsilva/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def tokenize(s):\n",
    "    return nltk.word_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4456762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rafaelsilva/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import*\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def stem_and_lemmatize(l):\n",
    "    \n",
    "    lem_stem_list = [] \n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for word in l:\n",
    "        lem = lemmatizer.lemmatize(word)\n",
    "        stem = stemmer.stem(lem)\n",
    "        lem_stem_list.append(stem)\n",
    "    \n",
    "    return lem_stem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e24d550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rafaelsilva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(l):    \n",
    "    \n",
    "    filtered_sentence = [w for w in l if not w in stop_words]\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3473b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one(new_input):\n",
    "    \n",
    "    new_input=clean_up(new_input)\n",
    "    new_input=tokenize(new_input)\n",
    "    new_input=stem_and_lemmatize(new_input)\n",
    "    new_input=remove_stopwords(new_input)\n",
    "    \n",
    "    return new_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4f20c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mv/pzkkwg_132x_kq3wgrqvf2jr0000gn/T/ipykernel_4846/4038282554.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample['processed']=sample['text'].apply(all_in_one)\n"
     ]
    }
   ],
   "source": [
    "sample['processed']=sample['text'].apply(all_in_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52bcb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>4377</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>ARGENTINA</td>\n",
       "      <td>#Earthquake #Sismo M 1.9 - 15km E of Anchorage...</td>\n",
       "      <td>1</td>\n",
       "      <td>[earthquak, sismo, km, e, anchorag, alaska, ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>3408</td>\n",
       "      <td>derail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@EmiiliexIrwin Totally agree.She is 23 and kno...</td>\n",
       "      <td>0</td>\n",
       "      <td>[emiiliexirwin, total, agre, know, birth, cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>9794</td>\n",
       "      <td>trapped</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hollywood Movie About Trapped Miners Released ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[hollywood, movi, trap, miner, releas, chile, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>10344</td>\n",
       "      <td>weapons</td>\n",
       "      <td>Beirut/Toronto</td>\n",
       "      <td>Friendly reminder that the only country to eve...</td>\n",
       "      <td>1</td>\n",
       "      <td>[friendli, remind, onli, countri, ever, use, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>1779</td>\n",
       "      <td>buildings%20on%20fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buildings are on fire and they have time for a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[build, fire, time, busi, meet, thestrain]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                keyword        location  \\\n",
       "6466   4377             earthquake       ARGENTINA   \n",
       "6467   3408                 derail             NaN   \n",
       "6468   9794                trapped             NaN   \n",
       "6469  10344                weapons  Beirut/Toronto   \n",
       "6470   1779  buildings%20on%20fire             NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "6466  #Earthquake #Sismo M 1.9 - 15km E of Anchorage...       1   \n",
       "6467  @EmiiliexIrwin Totally agree.She is 23 and kno...       0   \n",
       "6468  Hollywood Movie About Trapped Miners Released ...       1   \n",
       "6469  Friendly reminder that the only country to eve...       1   \n",
       "6470  Buildings are on fire and they have time for a...       1   \n",
       "\n",
       "                                              processed  \n",
       "6466  [earthquak, sismo, km, e, anchorag, alaska, ti...  \n",
       "6467  [emiiliexirwin, total, agre, know, birth, cont...  \n",
       "6468  [hollywood, movi, trap, miner, releas, chile, ...  \n",
       "6469  [friendli, remind, onli, countri, ever, use, n...  \n",
       "6470         [build, fire, time, busi, meet, thestrain]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46a2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "\n",
    "for tweet in sample['processed']:\n",
    "    for word in tweet:\n",
    "        new_list.append(word)\n",
    "        \n",
    "new_list=nltk.FreqDist(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abeb6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    \n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    \n",
    "    for w in new_list:\n",
    "        features[w] = (w in words)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016e7dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6387\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(find_features(tweet), target) for (tweet, target) in list(zip(sample['processed'], sample['target']))]\n",
    "\n",
    "print(len(featuresets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8847a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = featuresets[:round(len(featuresets)/2)]\n",
    "\n",
    "testing_set = featuresets[round(len(featuresets)/2):]\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44d2267b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7813968055120576"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, testing_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
